
@Misc{McGregor_BSc-2017,
  author =    {Léon McGregor},
  title =     {Web Platform for Code Peer-Testing},
  howpublished = {BSc Honours dissertation},
  month =     apr,
  year =      {2017},
}

@Comment{ruef_build_2016}
@Comment{October 24--28}
@inproceedings{Rue+Hic+Par+Lev+Mem+Pla+Mar_CCS-2016,
  author    = {Andrew Ruef and
               Michael W. Hicks and
               James Parker and
               Dave Levin and
               Michelle L. Mazurek and
               Piotr Mardziel},
  title     = {Build It, Break It, Fix It: Contesting Secure Development},
  booktitle = {{ACM} {SIGSAC} Conference on Computer and
               Communications Security (CCS)},
  address   = {Vienna, Austria},
  pages     = {690--703},
  year      = {2016},
  OPTdoi       = {10.1145/2976749.2978382},
}


@inproceedings{hooshangi_can_2015,
 title = {Can the Security Mindset Make Students Better Testers?},
 isbn = {978-1-4503-2966-8},
 OPTdoi = {10.1145/2676723.2677268},
 pages = {404--409},
 publisher = {{ACM} Press},
 author = {Hooshangi, Sara and Weiss, Richard and Cappos, Justin},
 year = {2015},
 langid = {english},
 keywords = {mm, security, w1},
 file = {hooshangi_sigcse15.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\JEQVK8WC\\hooshangi_sigcse15.pdf:application/pdf}
}

@inproceedings{farnqvist_competition_2016,
 title = {Competition and Feedback through Automated Assessment in a Data Structures and Algorithms Course},
 isbn = {978-1-4503-4231-5},
 booktitle = {ACM Conference on Innovation and Technology in Computer Science Education (ITiCSE '16)},
 OPTdoi = {10.1145/2899415.2899454},
 pages = {130--135},
 OPTpublisher = {{ACM} Press},
 author = {Färnqvist, Tommy and Heintz, Fredrik},
 urldate = {2016-09-18},
 year = {2016},
 langid = {english},
 keywords = {automated test, mm, w1},
 file = {p130-farnqvist.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\PABIRCRV\\p130-farnqvist.pdf:application/pdf}
}

@inproceedings{smith_using_2012,
 title = {Using peer review to teach software testing},
 isbn = {978-1-4503-1604-0},
 OPTdoi = {10.1145/2361276.2361295},
 pages = {93--98},
 booktitle = {Ninth Annual International Conference on International Computing Education Research (ICER ’12)},
 publisher = {{ACM}},
 author = {Smith, Joanna and Tessler, Joe and Kramer, Elliot and Lin, Calvin},
 year = {2012},
 langid = {english},
 keywords = {mm, peertest, w1},
 file = {p93-smith.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\UM26EJ5H\\p93-smith.pdf:application/pdf}
}


@online{moodle_about_2016,
 title = {About Moodle - {MoodleDocs}},
 url = {https://docs.moodle.org/31/en/},
 author = {Moodle},
 urldate = {2016-09-26},
 year = {2016},
 keywords = {mm, vle, w2},
 file = {About Moodle - MoodleDocs:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\HXT3IISD\\About_Moodle.html:text/html}
}

@inproceedings{sitthiworachart_effective_2004,
 title = {Effective peer assessment for learning computer programming},
 isbn = {978-1-58113-836-8},
 OPTdoi = {10.1145/1007996.1008030},
 pages = {122},
 publisher = {{ACM} Press},
 author = {Sitthiworachart, Jirarat and Joy, Mike},
 year = {2004},
 langid = {english},
 keywords = {lm, peertest, w3},
 file = {p122-sitthiworachart.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\8MGWCRVX\\p122-sitthiworachart.pdf:application/pdf}
}

@article{li_role_2016,
 title = {The role of anonymity in peer assessment},
 issn = {0260-2938, 1469-297X},
 OPTdoi = {10.1080/02602938.2016.1174766},
 pages = {1--12},
 journal = {Assessment \& Evaluation in Higher Education},
 author = {Li, Lan},
 year = {2016},
 month = apr,
 date = {2016-04-22},
 langid = {english},
 keywords = {lm, peertest, w3},
 file = {The role of anonymity in peer assessment.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\3PCRJV2T\\The role of anonymity in peer assessment.pdf:application/pdf}
}

@article{schreuders_empowering_2011,
 title = {Empowering End Users to Confine Their Own Applications: The Results of a Usability Study Comparing {SELinux}, {AppArmor}, and {FBAC}-{LSM}},
 volume = {14},
 issn = {10949224},
 OPTdoi = {10.1145/2019599.2019604},
 shorttitle = {Empowering End Users to Confine Their Own Applications},
 pages = {1--28},
 number = {2},
 journal = {{ACM} Transactions on Information and System Security},
 author = {Schreuders, Z. Cliffe and {McGill}, Tanya and Payne, Christian},
 year = {2011},
 month = sep,
 date = {2011-09-01},
 langid = {english},
 keywords = {implement, lm, security, w3},
 file = {empowering_end_users.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\AVAEI48P\\empowering_end_users.pdf:application/pdf}
}

@article{egelberth_pybox-python_2016,
 title = {{PyBox}-A Python Sandbox},
 author = {Egelberth, Markus},
 year = {2016},
 keywords = {implement, lm, w4},
 file = {4feca7dd6b7e2d14d40df4f23b155597592b.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\G7SATWZX\\4feca7dd6b7e2d14d40df4f23b155597592b.pdf:application/pdf}
}


@article{davies_computerized_2000,
 title = {Computerized Peer Assessment},
 volume = {37},
 issn = {1355-8005, 1469-8420},
 OPTdoi = {10.1080/135580000750052955},
 pages = {346--355},
 number = {4},
 journal = {Innovations in Education \& Training International},
 author = {Davies, Phil},
 year = {2000},
 OPTmonth = jan,
 langid = {english},
 keywords = {lm, peer test, w4},
 file = {Computerized Peer Assessment.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\FKE56K9K\\Computerized Peer Assessment.pdf:application/pdf}
}

@article{maarek_peer_2016,
 title = {Peer Testing as Peer Feedback},
 author = {Maarek, Manuel},
 year = {2016},
 keywords = {mm, peertest, w4},
 file = {Peer-Testing.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VHW2DZD6\\Peer-Testing.pdf:application/pdf}
}

@article{li_assessor_2010,
 title = {Assessor or assessee: How student learning improves by giving and receiving peer feedback},
 volume = {41},
 issn = {00071013, 14678535},
 OPTdoi = {10.1111/j.1467-8535.2009.00968.x},
 shorttitle = {Assessor or assessee},
 pages = {525--536},
 number = {3},
 journal = {British Journal of Educational Technology},
 author = {Li, Lan and Liu, Xiongyi and Steckelberg, Allen L.},
 year = {2010},
 month = may,
 langid = {english},
 keywords = {lm, peertest, w4},
 file = {j.1467-8535.2009.00968.x (1).pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VIE56K3T\\j.1467-8535.2009.00968.x (1).pdf:application/pdf}
}

@article{sorva_notional_2013,
 title = {Notional machines and introductory programming education},
 volume = {13},
 issn = {19466226},
 OPTdoi = {10.1145/2483710.2483713},
 pages = {1--31},
 number = {2},
 journal = {{ACM} Transactions on Computing Education},
 author = {Sorva, Juha},
 date = {2013-06-01},
 year = {2013},
 month = jun,
 langid = {english},
 keywords = {learning, mm, unread, w5},
 file = {ft_gateway.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\3MZ7D7A2\\ft_gateway.pdf:application/pdf}
}

@article{mogus_impact_2012,
 title = {The impact of student activity in a virtual learning environment on their final mark},
 volume = {13},
 issn = {1469-7874, 1741-2625},
 OPTdoi = {10.1177/1469787412452985},
 pages = {177--189},
 number = {3},
 journal = {Active Learning in Higher Education},
 author = {Mogus, A. M. and Djurdjevic, I. and Suvak, N.},
 year = {2012},
 month = nov,
 date = {2012-11-01},
 langid = {english},
 keywords = {lm, vle, w5},
 file = {Active Learning in Higher Education-2012-Mogus-177-89.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\9J4PJJ6P\\Active Learning in Higher Education-2012-Mogus-177-89.pdf:application/pdf}
}

@article{keppell_peer_2006,
 title = {Peer learning and learning-oriented assessment in technology-enhanced environments},
 volume = {31},
 issn = {0260-2938, 1469-297X},
 OPTdoi = {10.1080/02602930600679159},
 pages = {453--464},
 number = {4},
 journal = {Assessment \& Evaluation in Higher Education},
 author = {Keppell, Mike and Au, Eliza and Ma, Ada and Chan, Christine},
 year = {2006},
 month = aug,
 langid = {english},
 keywords = {lm, vle, w5},
 file = {Peer_learning_and_learning_oriented_asse.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VFR9T4BX\\Peer_learning_and_learning_oriented_asse.pdf:application/pdf}
}

@book{madeyski_test-driven_2010,
 location = {Berlin, Heidelberg},
 title = {Test-Driven Development},
 isbn = {978-3-642-04287-4 978-3-642-04288-1},
 publisher = {Springer Berlin Heidelberg},
 author = {Madeyski, Lech},
 year = {2010},
 langid = {english},
 keywords = {lm, software testing, tdd, w6},
 file = {bok%3A978-3-642-04288-1.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\JUGQX9A4\\bok%3A978-3-642-04288-1.pdf:application/pdf}
}

@online{hypothesis_most_2016,
 title = {Most testing is ineffective - Hypothesis},
 url = {http://hypothesis.works/},
 author = {Hypothesis},
 urldate = {2016-10-17},
 year = {2016},
 keywords = {lm, python, quickcheck, software testing, w6},
 file = {Most testing is ineffective - Hypothesis:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VA4G8BUT\\hypothesis.works.html:text/html}
}

@article{sadler_impact_2006,
 title = {The Impact of Self- and Peer-Grading on Student Learning},
 volume = {11},
 issn = {1062-7197},
 OPTdoi = {10.1207/s15326977ea1101_1},
 abstract = {The 2001 U.S. Supreme Court Case of Falvo v. Owasso School System (Owasso Independent School District No I-011 v. Falvo) has focused national attention on the common classroom practice of peer-grading. In a unanimous decision the court reaffirmed the popular view that students grading each others' tests is valuable, saving teachers' time and augmenting student learning. Our study puts these presumed benefits to the test in 4 middle school science classrooms. We compared teacher-assigned grades to those awarded either by students to themselves or by their peers. By training students to grade with the help of a scoring rubric, a very high correlation was obtained between students and their teacher on test questions (r = 0.91 to 0.94). We found patterns of bias when students assigned grades. When grading others, students awarded lower grades to the best performing students than their teacher did. When grading themselves, lower performing students tended to inflate their own low scores. Performance on an unannounced, 2nd administration of the same test 1 week later measured the degree to which student-grading resulted in any increased understanding. Students who graded their peers' tests did not gain significantly more than a control group of students who did not correct any papers but simply took the same test again. Those students who corrected their own tests improved dramatically. Self-grading and peer-grading appear to be reasonable aids to saving teachers' time. Self-grading appears to result in increased student learning; peer-grading does not.},
 pages = {1--31},
 number = {1},
 journal = {Educational Assessment},
 author = {Sadler, Philip M. and Good, Eddie},
 year = {2006},
 langid = {english},
 keywords = {Grading, lm, Peer Evaluation, Self Evaluation (Individuals), w7},
 file = {Sadler and Good EA.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\ZMWPW3T5\\Sadler and Good EA.pdf:application/pdf;Snapshot:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\DWUM27B4\\eric.ed.gov.html:text/html}
}

@inproceedings{buffardi_formative_2014,
 location = {New York, {NY}, {USA}},
 title = {A Formative Study of Influences on Student Testing Behaviors},
 isbn = {978-1-4503-2605-6},
 OPTurl = {http://doi.acm.org/10.1145/2538862.2538982},
 OPTdoi = {10.1145/2538862.2538982},
 series = {{SIGCSE} '14},
 abstract = {While Computer Science curricula teach students strategic software development processes, assessment is often product-instead of process-oriented. Test-Driven Development ({TDD}) has gained popularity in computing education, but evaluating students' adherence to {TDD} requires analyzing their development processes instead of only their final product. Consequently, we designed an adaptive feedback system for reinforcing incremental testing behaviors. In this paper, we compare the results of the system with different reinforcement schedules and with- or without- visually salient testing goals. We analyzed snapshots of students' programming projects gathered during development and interviewed students at the end of the academic term. From our findings, we identify potential for influencing student development behaviors and suggest future direction for designing adaptive reinforcement.},
 pages = {597--602},
 booktitle = {45th {ACM} Technical Symposium on Computer Science Education},
 publisher = {{ACM}},
 author = {Buffardi, Kevin and Edwards, Stephen H.},
 year = {2014},
 keywords = {mm, test-driven development, unit testing, w7},
 file = {ACM Full Text PDF:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\MAI6JIIE\\Buffardi and Edwards - 2014 - A Formative Study of Influences on Student Testing.pdf:application/pdf}
}

@inproceedings{buffardi_impacts_2013,
 location = {New York, {NY}, {USA}},
 title = {Impacts of Adaptive Feedback on Teaching Test-driven Development},
 isbn = {978-1-4503-1868-6},
 OPTdoi = {10.1145/2445196.2445287},
 series = {{SIGCSE} '13},
 abstract = {Studies have found that following Test-Driven Development ({TDD}) can improve code and testing quality. However, a preliminary investigation was consistent with concerns raised by other educators about programmers resisting {TDD}. In this paper, we describe an adaptive, pedagogical system for tracking and encouraging students' adherence to {TDD}. Along with an empirical evaluation of the system, we discuss challenges and opportunities for persuading student behavior through adaptive technology.},
 pages = {293--298},
 booktitle = {44th {ACM} Technical Symposium on Computer Science Education},
 publisher = {{ACM}},
 author = {Buffardi, Kevin and Edwards, Stephen H.},
 year = {2013},
 keywords = {automated test, mm, test-driven development ({TDD}), unit testing, w7},
 file = {ACM Full Text PDF:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\NIMXDG4Q\\Buffardi and Edwards - 2013 - Impacts of Adaptive Feedback on Teaching Test-driv.pdf:application/pdf}
}

@inproceedings{jeuring_model_2014,
 location = {New York, {NY}, {USA}},
 title = {Model Solutions and Properties for Diagnosing Student Programs in Ask-Elle},
 isbn = {978-1-4503-3347-4},
 OPTdoi = {10.1145/2691352.2691355},
 series = {{CSERC} '14},
 abstract = {Ask-Elle is an interactive tutor that supports the stepwise development of simple functional programs. Using Ask-Elle students receive feedback about whether or not they are on the right track, they can ask for a hint when they are stuck, and get suggestions about how to refactor their program. Our tutor generates this feedback from model solutions and properties that a solution should satisfy. This paper studies the feasibility of using model solutions together with the desired properties of solutions to analyse the work of a student. It describes an experiment in which we analyse almost 3500 log entries from students using Ask-Elle to solve functional programming exercises, to determine how many of these programs are diagnosed correctly based on model solutions and the desired properties of solutions. Ask-Elle manages to correctly diagnose 82.9\% of the student programs. A further analysis of the student programs and the diagnoses shows that adding some reasonable model solutions, properties of model solutions, and general program transformations would increase this percentage to 92.9\%.},
 pages = {31--40},
 booktitle = {Computer Science Education Research Conference},
 publisher = {{ACM}},
 author = {Jeuring, Johan and van Binsbergen, L. Thomas and Gerdes, Alex and Heeren, Bastiaan},
 year = {2014},
 keywords = {functional programming, Haskell, mm, tutoring, w7},
 file = {ACM Full Text PDF:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\9H63ZFAU\\Jeuring et al. - 2014 - Model Solutions and Properties for Diagnosing Stud.pdf:application/pdf}
}

@inproceedings{earle_teaching_2014,
 title = {Teaching Students Property-Based Testing},
 OPTdoi = {10.1109/SEAA.2014.74},
 abstract = {Testing is a crucial aspect of the development of dependable embedded systems, and therefore a significant effort is put into researching and developing efficient testing techniques. However, testing is not normally taught in specific courses at many universities, but rather as a peripheral activity to programming. In this paper, we report on three separate experiences at teaching an advanced testing technique, property-based testing, and a supporting tool, {QuviQ} Quick Check, to both undergraduate and master students.},
 eventtitle = {2014 40th {EUROMICRO} Conference on Software Engineering and Advanced Applications},
 pages = {437--442},
 booktitle = {2014 40th {EUROMICRO} Conference on Software Engineering and Advanced Applications},
 author = {Earle, C. B. and Fredlund, L. Å and Mariño, J. and Arts, T.},
 year = {2014},
 month = aug,
 keywords = {Java, mm, property-based testing, quickcheck, software testing, w7},
 file = {IEEE Xplore Abstract Record:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VQXZ9SAM\\6928850.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\7K8K3ZN2\\Earle et al. - 2014 - Teaching Students Property-Based Testing.pdf:application/pdf}
}



@Book{laboon_friendly_2016,
  author =    {Bill Laboon},
  title =        {A Friendly Introduction to Software Testing},
  publisher =    {CreateSpace Independent Publishing Platform},
  year =         {2016},
  edition =   {1},
}

@online{blackboard_blackboard_2016,
 title = {Blackboard Learn - Learning Management System},
 url = {https://www.blackboard.com/learning-management-system/blackboard-learn.aspx},
 abstract = {Blackboard Learn helps customers optimize their learning management systems with implementation services and training to create new learning experiences.},
 author = {Blackboard},
 urldate = {2016-10-27},
 year = {2016},
 keywords = {lm, vle, w7},
 file = {Snapshot:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\ZRC46X8W\\blackboard-learn.html:text/html}
}

@inproceedings{goldwasser_gimmick_2002,
 location = {New York, {NY}, {USA}},
 title = {A Gimmick to Integrate Software Testing Throughout the Curriculum},
 isbn = {978-1-58113-473-5},
 OPTdoi = {10.1145/563340.563446},
 series = {{SIGCSE} '02},
 abstract = {We discuss our experiences in which students of a programming course were asked to submit both an implementation as well as a test set. A portion of a student's grade was then devoted both to the validity of a student's program on others' test sets, as well as how that student's test set performed in uncovering flaws in others' programs. The advantages are many, as this introduces implicit principles of software testing together with a bit of fun competition. The major complication is that such an all-pairs execution of tests grows quadratically with the number of participants, necessitating a fully automated scoring system.},
 pages = {271--275},
 booktitle = {33rd {SIGCSE} Technical Symposium on Computer Science Education},
 publisher = {{ACM}},
 author = {Goldwasser, Michael H.},
 year = {2002},
 keywords = {lm, software testing, w7},
 file = {p271-goldwasser.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\B3KISHJW\\p271-goldwasser.pdf:application/pdf}
}

@online{goldwasser_autograde_2002,
 title = {Autograde Package},
 url = {http://cs.slu.edu/~goldwasser/autograde/},
 titleaddon = {User's Guide for autograde},
 author = {Goldwasser, Michael H.},
 urldate = {2016-10-31},
 year = {2002},
 keywords = {lm, perl, software testing, w8},
 file = {autograde package:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\G2MS8NQ6\\autograde.html:text/html;userguide.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\XBXNV9T5\\userguide.pdf:application/pdf}
}

@online{ubuntu_basic_2016,
 title = {Basic Chroot},
 url = {https://help.ubuntu.com/community/BasicChroot},
 titleaddon = {Basic Chroot},
 author = {Ubuntu},
 urldate = {2016-10-31},
 year = {2016},
 keywords = {chroot, security, w8},
 file = {BasicChroot - Community Help Wiki:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\U4N3M4FU\\BasicChroot.html:text/html}
}

@online{pypy.js_web_2016,
 title = {Web based python interpreter - {PyPy}.js},
 url = {http://pypyjs.org/},
 author = {{PyPy}.js},
 urldate = {2016-10-31},
 year = {2016},
 keywords = {implement, lm, python, w8},
 file = {PyPy.js:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\CUZD2N8X\\pypyjs.org.html:text/html}
}

@book{falchikov_improving_2013,
 title = {Improving Assessment Through Student Involvement: Practical Solutions for Aiding Learning in Higher and Further Education},
 isbn = {978-1-134-39575-0},
 shorttitle = {Improving Assessment Through Student Involvement},
 abstract = {The assessment of students an activity central to the role of any professional in further and higher education, and is an area that is the subject of constant innovation and debate. This book provides a scholarly account of the many facets of assessment, with a particular focus on student involvement. Peer and self-assessment are powerful assessment tools to add to the existing tutor-based methods of assessment and feedback, and this book is a comprehensive guide to the the methods and issues involved.Practical and accessible in style, yet grounded in research and rich in evidence-based material, Improving Assessment Through Student Involvement will be valued by all {FE} or {HE} professionals wanting to enhance both the effectiveness and quality of their assessment methods.},
 pagetotal = {305},
 publisher = {Routledge},
 author = {Falchikov, Nancy},
 year = {2013},
 month = apr,
 date = {2013-04-15},
 langid = {english},
 keywords = {education, mm, Peer Evaluation, w8},
 file = {Ch5.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\Z3G7TWS2\\Ch5.pdf:application/pdf}
}

@inproceedings{enstrom_five_2011,
 title = {Five years with Kattis — Using an automated assessment system in teaching},
 isbn = {978-1-61284-468-8},
 OPTdoi = {10.1109/FIE.2011.6142931},
 abstract = {Automated assessment systems have been employed in computer science ({CS}) courses at a number of different universities. Such systems are especially applicable in teaching algorithmic problem solving since they can automatically test if an algorithm has been correctly implemented, i.e., that it performs its specified function on a set of inputs. Being able to implement algorithms that work correctly is a crucial skill for {CS} students in their professional role, but it can be difficult to convey the importance of this in a classroom situation. Programming and problem solving education supported by automated grading has been used since 2002 at our department. We study, using action research methodology, different strategies for deploying automated assessment systems in {CS} courses. Towards this end, we have developed an automated assessment system and both introduced it into existing courses and constructed new courses structured around it. Our primary data sources for evaluation consists of course evaluations, statistics on students' submitted solutions, and experience teaching the courses. Authors of this paper have been participating in teaching all of the courses mentioned here.},
 OPTpages = {T3J--1--T3J--6},
 booktitle = {Frontiers in Education Conference ({FIE}), 2011},
 publisher = {{IEEE} Publishing},
 author = {Enstrom, Emma and Kreitz, Gunnar and Niemela, Fredrik and Soderman, Pehr and Kann, Viggo},
 year = {2011},
 keywords = {automated test, lm, software testing, w8},
 file = {kattis-fie11.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\IIJBFB4X\\kattis-fie11.pdf:application/pdf}
}

@article{higgins_coursemarker_2003,
 title = {The {CourseMarker} {CBA} System: Improvements over Ceilidh},
 volume = {8},
 issn = {1360-2357, 1573-7608},
 OPTdoi = {10.1023/A:1026364126982},
 shorttitle = {The {CourseMarker} {CBA} System},
 abstract = {This document reports on the results of re-designing and re-implementing the Ceilidh courseware system. It highlights the limitations identified in the thirteen years of Ceilidh's use at the University of Nottingham. It also illustrates how most of these limitations have been resolved by re-designing Ceilidh's architecture and improving various aspects of the marking and administrating processes. The new system, entitled {CourseMarker}, offers enhanced functionality by adding useful features that have long been needed by Ceilidh's community. The paper concludes with an evaluation of the changes and a brief report on the experience of {CourseMarker}'s use over the last three years. Finally, recent developments and future directions are discussed.},
 pages = {287--304},
 number = {3},
 journal = {Education and Information Technologies},
 shortjournal = {Education and Information Technologies},
 author = {Higgins, Colin and Hegazy, Tarek and Symeonidis, Pavlos and Tsintsifas, Athanasios},
 year = {2003},
 langid = {english},
 keywords = {ceilidh, lm, w8},
 file = {Full Text PDF:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\V8T2RCZU\\Higgins et al. - The CourseMarker CBA System Improvements over Cei.pdf:application/pdf;Snapshot:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\VMHP78GT\\A1026364126982.html:text/html}
}

@article{foubister_automatic_1997,
 title = {Automatic assessment of elementary Standard {ML} programs using Ceilidh},
 volume = {13},
 OPTurl = {http://onlinelibrary.wiley.com/doi/10.1046/j.1365-2729.1997.00012.x/abstract},
 pages = {99--108},
 number = {2},
 journal = {Journal of Computer Assisted Learning},
 author = {Foubister, Sandra P. and Michaelson, G. J. and Tomes, Nils},
 urldate = {2016-11-03},
 year = {1997},
 keywords = {ceilidh, lm, w8},
 file = {Foubister_et_al-1997-Journal_of_Computer_Assisted_Learning.pdf:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\FEF5H5E7\\Foubister_et_al-1997-Journal_of_Computer_Assisted_Learning.pdf:application/pdf}
}

@online{github_project_2016,
 title = {Project Code Review},
 url = {https://github.com/features/projects/codereview},
 abstract = {{GitHub} is where people build software. More than 18 million people use {GitHub} to discover, fork, and contribute to over 49 million projects.},
 author = {{GitHub}},
 urldate = {2016-11-08},
 year = {2016},
 file = {Snapshot:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\XWAA2PNM\\codereview.html:text/html}
}

@article{topping_peer_2009,
 title = {Peer Assessment},
 volume = {48},
 issn = {00405841},
 OPTdoi = {10.1080/00405840802577569},
 abstract = {Peer assessment is an arrangement for learners to consider and specify the level, value, or quality of a product or performance of other equal-status learners. Products to be assessed can include writing, oral presentations, portfolios, test performance, or other skilled behaviors. Peer assessment can be summative or formative. A formative view is presented here, in which the intent is to help students help each other plan their learning, identify their strengths and weaknesses, target areas for remedial action, and develop metacognitive and other personal and professional skills. Peer feedback is available in greater volume and with greater immediacy than teacher feedback. A peer assessor with less skill at assessment but more time in which to do it can produce an assessment of equal reliability and validity to that of a teacher. This article describes effective approaches to peer assessment and encourages teachers to incorporate it into their practice.},
 pages = {20--27},
 number = {1},
 journal = {Theory Into Practice},
 shortjournal = {Theory Into Practice},
 author = {Topping, Keith J.},
 year = {2009},
 keywords = {education, Peer Evaluation, w9},
 file = {EBSCO Full Text:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\3A9AKPHD\\Topping - 2009 - Peer Assessment.pdf:application/pdf}
}

@online{pypy_pypy_2016,
 title = {{PyPy} - What is {PyPy}?},
 url = {http://pypy.org/features.html},
 author = {{PyPy}},
 urldate = {2016-11-10},
 year = {2016},
 file = {PyPy - What is PyPy?:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\3EPHHN44\\features.html:text/html}
}

@online{davies_review_2016,
 title = {Review in Computerized Peer- Assessment},
 url = {http://slideplayer.com/slide/8559667/},
 abstract = {Review in Computerized Peer- Assessment Dr Phil Davies Department of Computing Division of Computing \& Mathematical Sciences {FAT} University of Glamorgan. - ppt download},
 titleaddon = {Review in Computerized Peer- Assessment},
 author = {Davies, Phil},
 urldate = {2017-03-06},
 year = {2016},
 file = {8559667.ppt:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\ARF4XK7V\\8559667.ppt:application/msword;Review in Computerized Peer- Assessment Dr Phil Davies Department of Computing Division of Computing & Mathematical Sciences FAT University of Glamorgan. - ppt download:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\KJ3NZ7N3\\8559667.html:text/html}
}

@online{python_software_foundation_pep_2010,
 title = {{PEP} 3333 -- Python Web Server Gateway Interface v1.0.1},
 url = {https://www.python.org/dev/peps/pep-3333/},
 titleaddon = {Python.org},
 author = {Python Software Foundation},
 urldate = {2017-03-31},
 year = {2010},
 month = oct,
 date = {2010-10-26},
 file = {Snapshot:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\E3NZZSBZ\\pep-3333.html:text/html}
}

@online{django_channels_2016,
 title = {Channels — Channels 1.1.1 documentation},
 url = {https://channels.readthedocs.io/en/stable/index.html},
 author = {Django},
 urldate = {2017-03-31},
 year = {2016},
 file = {Django Channels — Channels 1.1.1 documentation:C\:\\Users\\lonm\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\qs5pc95q.default\\zotero\\storage\\ACNRBJV8\\index.html:text/html}
}

@inproceedings{GroHamKumMaaMcGrShaWelZan_STEM-HE-2017,
 address = {Edinburgh, UK},
 title = {Transition from passive learner to critical evaluator through peer-testing of programming artifacts},
 author = {Gudmund Grov and Mohammad Hamdan and Smitha S Kumar and Manuel Maarek and Léon McGregor and Talal Shaikh and J.B. Wells and Hind Zantout},
 booktitle = {Horizons in STEM Higher Education Conference: Making Connections and Sharing Pedagogy},
 year = {2017},
 month = jun,
 note = {(presentation in June 2017, paper in preparation)}
}




@inproceedings{Pha+Sin+Lis+Fil+Sch_ICSE-2013,
  title = {Creating a Shared Understanding of Testing Culture on a Social Coding Site},
  OPTdoi = {10.1109/ICSE.2013.6606557},
  abstract = {Many software development projects struggle with creating and communicating a testing culture that is appropriate for the project's needs. This may degrade software quality by leaving defects undiscovered. Previous research suggests that social coding sites such as GitHub provide a collaborative environment with a high degree of social transparency. This makes developers' actions and interactions more visible and traceable. We conducted interviews with 33 active users of GitHub to investigate how the increased transparency found on GitHub influences developers' testing behaviors. Subsequently, we validated our findings with an online questionnaire that was answered by 569 members of GitHub. We found several strategies that software developers and managers can use to positively influence the testing behavior in their projects. However, project owners on GitHub may not be aware of them. We report on the challenges and risks caused by this and suggest guidelines for promoting a sustainable testing culture in software development projects.},
  timestamp = {2016-09-15T14:52:00Z},
  booktitle = {2013 35th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author = {Pham, R. and Singer, L. and Liskin, O. and Filho, F. F. and Schneider, K.},
  month = may,
  year = {2013},
  keywords = {collaborative environment,Encoding,github,groupware,Guidelines,Interviews,Media,online questionnaire,program testing,social coding site,social networking (online),social transparency,Sociology,Software,software development projects,software quality,sustainable testing culture,Testing},
  pages = {112--121},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/E6UQM7SG/Pham et al. - 2013 - Creating a shared understanding of testing culture.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/DNG44WQP/6606557.html:text/html}
}

@inproceedings{Long_ISSTA-2015,
  address = {New York, NY, USA},
  series = {ISSTA 2015},
  title = {Collaborative {{Testing Across Shared Software Components}} ({{Doctoral Symposium}})},
  isbn = {978-1-4503-3620-8},
  OPTdoi = {10.1145/2771783.2784774},
  abstract = {Components of numerous component-based software systems are often developed and tested by multiple stakeholders, and there often exists significant overlap and synergy in the processes of testing systems with shared components. This work demonstrates that testers of shared software components can save effort by avoiding redundant work, and improve the test quality of each component as well as overall software systems by using information obtained when testing across multiple components. My research contains three parts. First, I investigate current testing practices for component-based software systems to find the overlap and synergy we conjecture exists. Second, I design and implement infrastructure and related tools to facilitate communication and data sharing between testers. Third, I design various testing processes to implement different collaborative testing algorithms and apply them to large actively developed software systems.},
  timestamp = {2016-09-15T14:53:01Z},
  urldate = {2016-09-15},
  booktitle = {{{International Symposium}} on {{Software Testing}} and {{Analysis}}},
  publisher = {{ACM}},
  author = {Long, Teng},
  year = {2015},
  keywords = {Collaborative Software Testing,Component-based Software},
  pages = {436--439},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/DIZSDQDI/Long - 2015 - Collaborative Testing Across Shared Software Compo.pdf:application/pdf}
}

@article{Zhu+Zha_TSC-2012,
  title = {Collaborative {{Testing}} of {{Web Services}}},
  volume = {5},
  issn = {1939-1374},
  OPTdoi = {10.1109/TSC.2010.54},
  abstract = {Software testers are confronted with great challenges in testing Web Services (WS) especially when integrating to services owned by other vendors. They must deal with the diversity of implementation techniques used by the other services and to meet a wide range of test requirements. However, they are in lack of software artifacts, the means of control over test executions and observation on the internal behavior of the other services. An automated testing technique must be developed to be capable of testing on-the-fly nonintrusively and nondisruptively. Addressing these problems, this paper proposes a framework of collaborative testing in which test tasks are completed through the collaboration of various test services that are registered, discovered, and invoked at runtime using the ontology of software testing STOWS. The composition of test services is realized by using test brokers, which are also test services but specialized in the coordination of other test services. The ontology can be extended and updated through an ontology management service so that it can support a wide open range of test activities, methods, techniques, and types of software artifacts. The paper presents a prototype implementation of the framework in semantic WS and demonstrates the feasibility of the framework by running examples of building a testing tool as a test service, developing a service for test executions of a WS, and composing existing test services for more complicated testing tasks. Experimental evaluation of the framework has also demonstrated its scalability.},
  timestamp = {2016-09-15T14:56:08Z},
  number = {1},
  journal = {IEEE Transactions on Services Computing},
  author = {Zhu, H. and Zhang, Y.},
  month = jan,
  year = {2012},
  keywords = {automated testing technique,Collaboration,collaborative testing,distributed/internet based software engineering tools and techniques,groupware,Insurance,internal behavior,Ontologies,ontology,ontology management service,program testing,Semantics,semantic web services,service composition.,Software,software artifacts,Software Engineering,software testers,software testing,STOWS,testing tools,test requirements,Web services,WS},
  pages = {116--130},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/VNTKHMTF/Zhu and Zhang - 2012 - Collaborative Testing of Web Services.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/6R5JDDNZ/5674012.html:text/html}
}

@inproceedings{Lon+Yoo+Por+Mem_Sus_ICST-2016,
  title = {Coordinated {{Collaborative Testing}} of {{Shared Software Components}}},
  OPTdoi = {10.1109/ICST.2016.38},
  abstract = {Software developers commonly build their software systems by reusing other components developed and maintained by third-party developer groups. As the components evolve over time, new end-user machine configurations that contain new component versions will be added continuously for the potential user base. Therefore developers must test whether their components function correctly in the new configurations to ensure the quality of the overall systems. This would be achievable if developers could provision the configurations in house and conduct regression testing over the configurations. However, this is often very time-consuming and also there can be redundancy in test effort between developers when a common set of components is reused for providing the functionality of the systems. In this paper, we present a coordinated collaborative regression testing process for multiple developer groups. It involves a scheduling method for distributing test effort across the groups at component updates, with the objectives of reducing test redundancy between the groups and also shortening the time window in which compatibility faults are exposed to user community. The process is implemented on Conch, a collaborative test data repository and services we developed in our previous work. Conch has been modified to function as the test process coordinator, as well as the shared repository of test data. Our experiments over the 1.5-year evolution history of eleven components in the Ubuntu developer community show that developers can quickly discover compatibility faults by applying the coordinated process. Moreover, total testing time is comparable to the scenario where the developers conduct regression testing only at updates of their own components.},
  timestamp = {2016-09-15T14:57:28Z},
  booktitle = {2016 {{IEEE International Conference}} on {{Software Testing}}, {{Verification}} and {{Validation}} ({{ICST}})},
  author = {Long, T. and Yoon, I. and Porter, A. and Memon, A. and Sussman, A.},
  month = apr,
  year = {2016},
  keywords = {Collaboration,compatibility faults,component updates,Conch collaborative test data repository,configuration management,coordinated collaborative regression testing process,coordinated collaborative testing,end-user machine configurations,History,object-oriented programming,program testing,Redundancy,scheduling,scheduling method,shared software components,software quality,Software systems,Testing,test redundancy reduction,third-party software developer groups,Ubuntu developer community,Virtual machining},
  pages = {364--374},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/2H7B22S6/Long et al. - 2016 - Coordinated Collaborative Testing of Shared Softwa.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/DN45594S/7515487.html:text/html}
}

@article{CMS_EPTCS-2014,
  title = {Verifying {{Web Applications}}: {{From Business Level Specifications}} to {{Automated Model}}-{{Based Testing}}},
  volume = {141},
  issn = {2075-2180},
  shorttitle = {Verifying {{Web Applications}}},
  OPTdoi = {10.4204/EPTCS.141.2},
  abstract = {One of reasons preventing a wider uptake of model-based testing in the industry is the difficulty which is encountered by developers when trying to think in terms of properties rather than linear specifications. A disparity has traditionally been perceived between the language spoken by customers who specify the system and the language required to construct models of that system. The dynamic nature of the specifications for commercial systems further aggravates this problem in that models would need to be rechecked after every specification change. In this paper, we propose an approach for converting specifications written in the commonly-used quasi-natural language Gherkin into models for use with a model-based testing tool. We have instantiated this approach using QuickCheck and demonstrate its applicability via a case study on the eHealth system, the national health portal for Maltese residents.},
  timestamp = {2017-02-09T13:08:27Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1403.7258},
  urldate = {2017-02-09},
  journal = {Electronic Proceedings in Theoretical Computer Science},
  author = {Colombo, Christian and Micallef, Mark and Scerri, Mark},
  month = mar,
  year = {2014},
  keywords = {Computer Science - Software Engineering,D.2.4,D.2.5},
  pages = {14--28},
  file = {arXiv\:1403.7258 PDF:/home/mm894/Documents/Zotero/storage/7J9XQ9U4/Colombo et al. - 2014 - Verifying Web Applications From Business Level Sp.pdf:application/pdf;arXiv.org Snapshot:/home/mm894/Documents/Zotero/storage/6ABPNHQ2/1403.html:text/html}
}

@inproceedings{LT_P9IWAST-2014,
  address = {New York, NY, USA},
  series = {AST 2014},
  title = {Improved {{Semantics}} and {{Implementation Through Property}}-Based {{Testing}} with {{QuickCheck}}},
  isbn = {978-1-4503-2858-6},
  OPTdoi = {10.1145/2593501.2593509},
  abstract = {Testing is the primary method to validate that a software implementation meets its specification. In this paper, we demonstrate an approach to validating an executable semantics using property- and model-based random testing in QuickCheck to automate and unify the testing of the semantics and its implementation. Our approach shows the use of executable semantics to bridge the gap between formal mathematical specification and implementation, as well as emphasising the suitability of functional programming languages -- in this case Erlang -- for writing executable semantics.   The approach is illustrated through a concrete example, in which the implementation of a proposed extension to the Erlang programming language -- scalable groups -- is tested. This new component comes with a small-step operational semantics written in mathematical notation, and was initially tested using unit testing. Through our work, we were able to find new bugs in both the implementation and the specification.},
  timestamp = {2017-04-03T00:27:24Z},
  urldate = {2017-04-03},
  booktitle = {9th {{International Workshop}} on {{Automation}} of {{Software Test}}},
  publisher = {{ACM}},
  author = {Li, Huiqing and Thompson, Simon},
  year = {2014},
  keywords = {Erlang,Executable Semantics,Implementation,Property-Based Testing,QuickCheck,specification,Testing},
  pages = {50--56},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/NA9HPEV2/Li and Thompson - 2014 - Improved Semantics and Implementation Through Prop.pdf:application/pdf},
  groups = {BDD-QC}
}

@book{Morris_IaC-2016,
  title = {Infrastructure as {{Code}}},
  isbn = {978-1-4919-2435-8},
  abstract = {Virtualization, cloud, containers, server automation, and software-defined networking are meant to simplify IT operations. But many organizations adopting these technologies have found that it only leads to a faster-growing sprawl of unmanageable...},
  timestamp = {2016-11-03T14:29:58Z},
  urldate = {2016-09-22},
  author = {Morris, Kief},
  year = {2016},
  file = {Snapshot:/home/mm894/Documents/Zotero/storage/KNU3RNUW/0636920039297.html:text/html},
  groups = {Cloud-Computing}
}

@inproceedings{AC_VV2ISICST-2014,
  title = {Data-{{Flow Testing}} in the {{Large}}},
  OPTdoi = {10.1109/ICST.2014.19},
  abstract = {Data-flow (DF) testing was introduced more than thirty years ago aiming at extensively evaluating a program structure. It requires tests that traverse a path in which the definition of a variable and its subsequent use, i.e., a definition-use association (dua), is exercised. While control-flow testing tools have being able to tackle big systems-large and long running programs, DF testing tools have failed to do so. This situation is in part due to the costs associated with tracking duas at run-time. Recently, an algorithm, called Bitwise Algorithm (BA), which uses bit vectors and bitwise operations for tracking intra-procedural duas at run-time, was proposed. This paper presents the implementation of BA for programs compiled into bytecodes. Previous approaches were able to deal with small to medium size programs with high penalties in terms of execution and memory. Our experimental results show that by using BA we are able to tackle large systems with more than 200 KLOCs and 300K required duas. Furthermore, for several programs the execution penalty was comparable with that imposed by a popular control-flow testing tool.},
  timestamp = {2017-01-10T01:15:08Z},
  booktitle = {Verification and {{Validation}} 2014 {{IEEE Seventh International Conference}} on {{Software Testing}}},
  author = {d Araujo, R. P. A. and Chaim, M. L.},
  month = mar,
  year = {2014},
  keywords = {Arrays,Barium,bit vectors,bitwise algorithm,bitwise operations,bytecodes,Bytecode testing,control-flow testing tools,data flow analysis,data-flow testing,Data-flow testing coverage,definition-use association,DF testing tools,intraprocedural dua tracking,java,Monitoring,Probes,Program instrumentation,program testing,Run-time environments,Software tools,Structural testing,Testing},
  pages = {81--90},
  groups = {Cloud-Computing}
}

@article{RHL+_JoSaS-2017,
  title = {Continuous Deployment of Software Intensive Products and Services: {{A}} Systematic Mapping Study},
  volume = {123},
  issn = {0164-1212},
  shorttitle = {Continuous Deployment of Software Intensive Products and Services},
  OPTdoi = {10.1016/j.jss.2015.12.015},
  abstract = {The software intensive industry is moving towards the adoption of a value-driven and adaptive real-time business paradigm. The traditional view of software as an item that evolves through releases every few months is being replaced by the continuous evolution of software functionality. This study aims to classify and analyse the literature related to continuous deployment in the software domain in order to scope the phenomenon, provide an overview of the state-of-the-art, investigate the scientific evidence in the reported results and identify areas suitable for further research. We conducted a systematic mapping study and classified the continuous deployment literature. The benefits and challenges related to continuous deployment were also analysed. RESULTS: The systematic mapping study includes 50 primary studies published between 2001 and 2014. An in-depth analysis of the primary studies revealed ten recurrent themes that characterize continuous deployment and provide researchers with directions for future work. In addition, a set of benefits and challenges of which practitioners may take advantage were identified. CONCLUSION: Overall, although the topic area is very promising, it is still in its infancy, thus offering a plethora of new opportunities for both researchers and software intensive companies.},
  timestamp = {2017-01-10T01:16:30Z},
  urldate = {2017-01-10},
  journal = {Journal of Systems and Software},
  author = {Rodr{\'\i}guez, Pilar and Haghighatkhah, Alireza and Lwakatare, Lucy Ellen and Teppola, Susanna and Suomalainen, Tanja and Eskeli, Juho and Karvonen, Teemu and Kuvaja, Pasi and Verner, June M. and Oivo, Markku},
  month = jan,
  year = {2017},
  keywords = {Continuous deployment,software development,Systematic mapping study},
  pages = {263--291},
  groups = {Cloud-Computing}
}

@inproceedings{Facebook_NASAFM-2015,
  series = {Lecture Notes in Computer Science},
  title = {Moving {{Fast}} with {{Software Verification}}},
  copyright = {\textcopyright{}2015 Springer International Publishing Switzerland},
  isbn = {978-3-319-17523-2 978-3-319-17524-9},
  abstract = {For organisations like Facebook, high quality software is important. However, the pace of change and increasing complexity of modern code makes it difficult to produce error-free software. Available tools are often lacking in helping programmers develop more reliable and secure applications. Formal verification is a technique able to detect software errors statically, before a product is actually shipped. Although this aspect makes this technology very appealing in principle, in practice there have been many difficulties that have hindered the application of software verification in industrial environments. In particular, in an organisation like Facebook where the release cycle is fast compared to more traditional industries, the deployment of formal techniques is highly challenging. This paper describes our experience in integrating a verification tool based on static analysis into the software development cycle at Facebook.},
  language = {en},
  timestamp = {2017-06-29T02:07:30Z},
  urldate = {2017-01-10},
  booktitle = {{{NASA Formal Methods}}},
  publisher = {{Springer International Publishing}},
  author = {Calcagno, Cristiano and Distefano, Dino and Dubreil, Jeremy and Gabi, Dominik and Hooimeijer, Pieter and Luca, Martino and O'Hearn, Peter and Papakonstantinou, Irene and Purbrick, Jim and Rodriguez, Dulma},
  editor = {Havelund, Klaus and Holzmann, Gerard and Joshi, Rajeev},
  month = apr,
  year = {2015},
  keywords = {Logics and Meanings of Programs,Mathematical Logic and Formal Languages,Operating Systems,Programming Languages; Compilers; Interpreters,Programming Techniques,Software Engineering},
  pages = {3--11},
  groups = {Cloud-Computing},
  OPTdoi = {10.1007/978-3-319-17524-9_1}
}

@inproceedings{RQRA_P1ICMSR-2016,
  address = {New York, NY, USA},
  series = {MSR '16},
  title = {Feature {{Toggles}}: {{Practitioner Practices}} and a {{Case Study}}},
  isbn = {978-1-4503-4186-8},
  shorttitle = {Feature {{Toggles}}},
  OPTdoi = {10.1145/2901739.2901745},
  abstract = {Continuous delivery and rapid releases have led to innovative techniques for integrating new features and bug fixes into a new release faster. To reduce the probability of integration conflicts, major software companies, including Google, Facebook and Netflix, use feature toggles to incrementally integrate and test new features instead of integrating the feature only when it's ready. Even after release, feature toggles allow operations managers to quickly disable a new feature that is behaving erratically or to enable certain features only for certain groups of customers. Since literature on feature toggles is surprisingly slim, this paper tries to understand the prevalence and impact of feature toggles. First, we conducted a quantitative analysis of feature toggle usage across 39 releases of Google Chrome (spanning five years of release history). Then, we studied the technical debt involved with feature toggles by mining a spreadsheet used by Google developers for feature toggle maintenance. Finally, we performed thematic analysis of videos and blog posts of release engineers at major software companies in order to further understand the strengths and drawbacks of feature toggles in practice. We also validated our findings with four Google developers. We find that toggles can reconcile rapid releases with long-term feature development and allow flexible control over which features to deploy. However they also introduce technical debt and additional maintenance for developers.},
  timestamp = {2017-01-10T01:01:16Z},
  urldate = {2017-01-10},
  booktitle = {13th {{International Conference}} on {{Mining Software Repositories}}},
  publisher = {{ACM}},
  author = {Rahman, Md Tajmilur and Querel, Louis-Philippe and Rigby, Peter C. and Adams, Bram},
  year = {2016},
  pages = {201--211},
  groups = {Cloud-Computing}
}

@book{HF_-2010,
  title = {Continuous {{Delivery}}: {{Reliable Software Releases}} through {{Build}}, {{Test}}, and {{Deployment Automation}} ({{Adobe Reader}})},
  isbn = {978-0-321-67022-9},
  shorttitle = {Continuous {{Delivery}}},
  abstract = {Winner of the 2011 Jolt Excellence Award!   Getting software released to users is often a painful, risky, and time-consuming process. This groundbreaking new book sets out the principles and technical practices that enable rapid, incremental delivery of high quality, valuable new functionality to users. Through automation of the build, deployment, and testing process, and improved collaboration between developers, testers, and operations, delivery teams can get changes released in a matter of hours\textemdash{} sometimes even minutes\textendash{}no matter what the size of a project or the complexity of its code base. ~ Jez Humble and David Farley begin by presenting the foundations of a rapid, reliable, low-risk delivery process. Next, they introduce the ``deployment pipeline,'' an automated process for managing all changes, from check-in to release. Finally, they discuss the ``ecosystem'' needed to support continuous delivery, from infrastructure, data and configuration management to governance. ~ The authors introduce state-of-the-art techniques, including automated infrastructure management and data migration, and the use of virtualization. For each, they review key issues, identify best practices, and demonstrate how to mitigate risks. Coverage includes ~ \textbullet{} Automating all facets of building, integrating, testing, and deploying software \textbullet{} Implementing deployment pipelines at team and organizational levels \textbullet{} Improving collaboration between developers, testers, and operations \textbullet{} Developing features incrementally on large and distributed teams \textbullet{} Implementing an effective configuration management strategy \textbullet{} Automating acceptance testing, from analysis to implementation \textbullet{} Testing capacity and other non-functional requirements \textbullet{} Implementing continuous deployment and zero-downtime releases \textbullet{} Managing infrastructure, data, components and dependencies \textbullet{} Navigating risk management, compliance, and auditing ~ Whether you're a developer, systems administrator, tester, or manager, this book will help your organization move from idea to release faster than ever\textemdash{}so you can deliver value to your business rapidly and reliably.},
  language = {en},
  timestamp = {2017-01-10T00:59:58Z},
  publisher = {{Pearson Education}},
  author = {Humble, Jez and Farley, David},
  month = jul,
  year = {2010},
  keywords = {Computers / Software Development \& Engineering / General},
  groups = {Cloud-Computing}
}

@inproceedings{SSC+_PFSE-2014,
  address = {New York, NY, USA},
  series = {FOSE 2014},
  title = {The ({{R}}) {{Evolution}} of {{Social Media}} in {{Software Engineering}}},
  isbn = {978-1-4503-2865-4},
  OPTdoi = {10.1145/2593882.2593887},
  abstract = {Software developers rely on media to communicate, learn, collaborate, and coordinate with others. Recently, social media has dramatically changed the landscape of software engineering, challenging some old assumptions about how developers learn and work with one another. We see the rise of the social programmer who actively participates in online communities and openly contributes to the creation of a large body of crowdsourced socio-technical content.   In this paper, we examine the past, present, and future roles of social media in software engineering. We provide a review of research that examines the use of different media channels in software engineering from 1968 to the present day. We also provide preliminary results from a large survey with developers that actively use social media to understand how they communicate and collaborate, and to gain insights into the challenges they face. We find that while this particular population values social media, traditional channels, such as face-to-face communication, are still considered crucial. We synthesize findings from our historical review and survey to propose a roadmap for future research on this topic. Finally, we discuss implications for research methods as we argue that social media is poised to bring about a paradigm shift in software engineering research.},
  timestamp = {2017-01-25T13:42:18Z},
  urldate = {2017-01-25},
  booktitle = {{{Future}} of {{Software Engineering}}},
  publisher = {{ACM}},
  author = {Storey, Margaret-Anne and Singer, Leif and Cleary, Brendan and Figueira Filho, Fernando and Zagalsky, Alexey},
  year = {2014},
  keywords = {Collaboration,Social Media,Software Engineering},
  pages = {100--116},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/T7U27FWU/Storey et al. - 2014 - The (R) Evolution of Social Media in Software Engi.pdf:application/pdf},
  groups = {Collaborative}
}

@inproceedings{ZFS+_P1ACCSCWSC-2015,
  address = {New York, NY, USA},
  series = {CSCW '15},
  title = {The {{Emergence}} of {{GitHub As}} a {{Collaborative Platform}} for {{Education}}},
  isbn = {978-1-4503-2922-4},
  OPTdoi = {10.1145/2675133.2675284},
  abstract = {The software development community has embraced GitHub as an essential platform for managing their software projects. GitHub has created efficiencies and helped improve the way software professionals work. It not only provides a traceable project repository, but it acts as a social meeting place for interested parties, supporting communities of practice. Recently, educators have seen the potential in GitHub's collaborative features for managing and improving---perhaps even transforming---the learning experience. In this study, we examine how GitHub is emerging as a collaborative platform for education. We aim to understand how environments such as GitHub---environments that provide social and collaborative features in conjunction with distributed version control---may improve (or possibly hinder) the educational experience for students and teachers. We conduct a qualitative study focusing on how GitHub is being used in education, and the motivations, benefits and challenges it brings.},
  timestamp = {2017-01-25T13:47:33Z},
  urldate = {2017-01-25},
  booktitle = {18th {{ACM Conference}} on {{Computer Supported Cooperative Work}} \& {{Social Computing}}},
  publisher = {{ACM}},
  author = {Zagalsky, Alexey and Feliciano, Joseph and Storey, Margaret-Anne and Zhao, Yiyun and Wang, Weiliang},
  year = {2015},
  keywords = {cscl,cscw,distributed version control,Education,github,learning,qualitative methodology,Social Media},
  pages = {1906--1917},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/F8RF8CB3/Zagalsky et al. - 2015 - The Emergence of GitHub As a Collaborative Platfor.pdf:application/pdf},
  groups = {Collaborative,CSE}
}

@inproceedings{SF_P1IWCSE-2014,
  address = {New York, NY, USA},
  series = {CSI-SE 2014},
  title = {Researching {{Crowdsourcing Software Development}}: {{Perspectives}} and {{Concerns}}},
  isbn = {978-1-4503-2857-9},
  shorttitle = {Researching {{Crowdsourcing Software Development}}},
  OPTdoi = {10.1145/2593728.2593731},
  abstract = {Crowdsourcing is an emerging form of `outsourcing' software development. While there has been considerable research in the area of crowdsourcing in general, very little research has focused specifically on how crowdsourcing works in a software development context, and as far as we know, there have been no published studies of crowdsourcing software development from a customer perspective. Based on a review of the literature, we identified a number of key concerns related to crowdsourcing that are of particular importance in a software development context. Furthermore, we observed a number of recurring key stakeholders, or actors, each of whom has a unique perspective on crowdsourcing. This paper presents a research framework that consists of the various combinations of stakeholders and key concerns. The framework can be used to guide future research on the use of crowdsourcing as a `sourcing' strategy, as well as a means to review and synthesize research findings so as to be able to compare studies on crowdsourcing in a software development context.},
  timestamp = {2017-01-25T13:51:37Z},
  urldate = {2017-01-25},
  booktitle = {1st {{International Workshop}} on {{CrowdSourcing}} in {{Software Engineering}}},
  publisher = {{ACM}},
  author = {Stol, Klaas-Jan and Fitzgerald, Brian},
  year = {2014},
  keywords = {crowdsourcing software development,research framework},
  pages = {7--10},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/HJP7HAP4/Stol and Fitzgerald - 2014 - Researching Crowdsourcing Software Development Pe.pdf:application/pdf},
  groups = {Collaborative}
}

@article{TWH_IIC-2014,
  title = {Cloud-{{Based Software Crowdsourcing}}},
  volume = {18},
  issn = {1089-7801},
  OPTdoi = {10.1109/MIC.2014.46},
  abstract = {In addition to providing large-scale, highly available computational resources, clouds also enable a new methodology for software development via crowdsourcing, in which crowd participants either collaborate or compete to contribute software. Using a crowd to develop software is predicted to take its place alongside established methodologies, such as agile, scrum, pair programming, service-oriented computing, and the traditional waterfall.},
  timestamp = {2017-01-25T13:51:44Z},
  number = {3},
  journal = {IEEE Internet Computing},
  author = {Tsai, W. T. and Wu, W. and Huhns, M. N.},
  month = may,
  year = {2014},
  keywords = {agile programming,cloud-based software crowdsourcing,Cloud computing,Collaboration,computational resources,Computer architecture,Crowdsourcing,Encoding,Paas,pair programming,platform-as-a-service,scrum programming,service-oriented computing,software development,Software Engineering,Testing,waterfall},
  pages = {78--83},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/SGP3UBJH/Tsai et al. - 2014 - Cloud-Based Software Crowdsourcing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/MFRHUCXW/6818962.html:text/html},
  groups = {Collaborative}
}

@article{MCHJ_JoSaS-,
  title = {A Survey of the Use of Crowdsourcing in Software Engineering},
  issn = {0164-1212},
  OPTdoi = {10.1016/j.jss.2016.09.015},
  abstract = {The term `crowdsourcing' was initially introduced in 2006 to describe an emerging distributed problem-solving model by online workers. Since then it has been widely studied and practiced to support software engineering. In this paper we provide a comprehensive survey of the use of crowdsourcing in software engineering, seeking to cover all literature on this topic. We first review the definitions of crowdsourcing and derive our definition of Crowdsourcing Software Engineering together with its taxonomy. Then we summarise industrial crowdsourcing practice in software engineering and corresponding case studies. We further analyse the software engineering domains, tasks and applications for crowdsourcing and the platforms and stakeholders involved in realising Crowdsourced Software Engineering solutions. We conclude by exposing trends, open issues and opportunities for future research on Crowdsourced Software Engineering.},
  timestamp = {2017-01-25T13:52:51Z},
  urldate = {2017-01-25},
  journal = {Journal of Systems and Software},
  author = {Mao, Ke and Capra, Licia and Harman, Mark and Jia, Yue},
  keywords = {Crowdsourced software engineering,Crowdsourcing,Literature survey,Software crowdsourcing},
  file = {ScienceDirect Full Text PDF:/home/mm894/Documents/Zotero/storage/AMNMFTUQ/Mao et al. - A survey of the use of crowdsourcing in software e.pdf:application/pdf;ScienceDirect Snapshot:/home/mm894/Documents/Zotero/storage/FZCUZ55W/S0164121216301832.html:text/html},
  groups = {Collaborative}
}

@techreport{NMM+_-2015,
  type = {Technical Report},
  title = {Using Software Changes to Understand the Test Driven Development Process},
  copyright = {http://creativecommons.org/licenses/by-nc-sa/3.0/us/},
  abstract = {A bad software development process leads to wasted effort and inferior products. In order to improve a software process, it is important to first understand it. Our unique approach in this paper is to use code and test changes to understand conformance to a process. We analyze the meaning of these changes to obtain a deep, rich understanding about the process. In this paper we use Test Driven Development (TDD) as a case study to validate our approach. We designed a visualization to enable developers to better understand their TDD software process. We analyze our visualization by using the Cognitive Dimensions framework to discuss some findings and design adjustments. To enable this visualization, we developed a novel automatic inferencer that identifies the phases that make up the TDD process solely based on code and test changes. We evaluate our TDD inferencer by performing an empirical evaluation on a corpus of 2601 TDD sessions. Our inferencer achieves an accuracy of 87\%.},
  language = {en\_US},
  timestamp = {2017-01-25T13:55:42Z},
  urldate = {2017-01-25},
  institution = {Corvallis, OR : Oregon State University, School of Electrical Engineering and Computer Science},
  author = {Nelson, Nicholas and McDonald, Hugh and McDonald, Sean and Metoyer, Ron and Dig, Danny and Hilton, Michael (Michael Edward) and Science, Oregon State University School of Electrical Engineering and Computer},
  year = {2015},
  file = {Full Text PDF:/home/mm894/Documents/Zotero/storage/F7E3CKRW/Nelson et al. - 2015 - Using software changes to understand the test driv.pdf:application/pdf;Snapshot:/home/mm894/Documents/Zotero/storage/CSF8CAT2/55027.html:text/html},
  groups = {Collaborative}
}

@inproceedings{DKSD_TP-2014,
  title = {Behaviour {{Driven Development}} for {{Tests}} and {{Verification}}},
  abstract = {The design of hardware systems is a challenging and error-prone task, where a signifcant portion of the effort is spent for testing and verification. Usually testing and verification are applied as a post-process to the implementation. Meanwhile, for the development of software, test-first approaches such as test driven development (TDD) have become increasingly important. In this paper, we propose a new design flow based on behaviour driven development (BDD), an extension of TDD, where acceptance tests written in natural language drive the implementation. We extend this idea by allowing the specification of properties in natural language and use them as a starting point in the design flow. The flow also includes an automatic generalisation of test cases to properties that are used for formal verification. In this way, testing and formal verification are combined in a seamless manner, while keeping the requirements \textemdash{} from which both tests and formal properties are derived \textemdash{} in a single consistent document. The approach has been implemented and evaluated on several examples to demonstrate the advantages of the proposed flow.},
  language = {en},
  timestamp = {2017-01-25T13:59:28Z},
  urldate = {2017-01-25},
  booktitle = {Tests and {{Proofs}}},
  publisher = {{Springer, Cham}},
  author = {Diepenbeck, Melanie and K{\"u}hne, Ulrich and Soeken, Mathias and Drechsler, Rolf},
  month = jul,
  year = {2014},
  pages = {61--77},
  file = {Full Text PDF:/home/mm894/Documents/Zotero/storage/UJGKSJ7C/Diepenbeck et al. - 2014 - Behaviour Driven Development for Tests and Verific.pdf:application/pdf;Snapshot:/home/mm894/Documents/Zotero/storage/5XDSVX4I/978-3-319-09099-3_5.html:text/html},
  groups = {Collaborative},
  OPTdoi = {10.1007/978-3-319-09099-3_5}
}

@inproceedings{PSLFS_ICSE2013,
  title = {Creating a Shared Understanding of Testing Culture on a Social Coding Site},
  OPTdoi = {10.1109/ICSE.2013.6606557},
  abstract = {Many software development projects struggle with creating and communicating a testing culture that is appropriate for the project's needs. This may degrade software quality by leaving defects undiscovered. Previous research suggests that social coding sites such as GitHub provide a collaborative environment with a high degree of social transparency. This makes developers' actions and interactions more visible and traceable. We conducted interviews with 33 active users of GitHub to investigate how the increased transparency found on GitHub influences developers' testing behaviors. Subsequently, we validated our findings with an online questionnaire that was answered by 569 members of GitHub. We found several strategies that software developers and managers can use to positively influence the testing behavior in their projects. However, project owners on GitHub may not be aware of them. We report on the challenges and risks caused by this and suggest guidelines for promoting a sustainable testing culture in software development projects.},
  timestamp = {2017-06-16T09:58:42Z},
  booktitle = {2013 35th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author = {Pham, R. and Singer, L. and Liskin, O. and Filho, F. F. and Schneider, K.},
  month = may,
  year = {2013},
  keywords = {collaborative environment,Encoding,github,groupware,Guidelines,Interviews,Media,online questionnaire,program testing,social coding site,social networking (online),social transparency,Sociology,Software,software development projects,software quality,sustainable testing culture,Testing},
  pages = {112--121},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/PMGQ4FMJ/Pham et al. - 2013 - Creating a shared understanding of testing culture.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/EZMR84PH/6606557.html:text/html},
  groups = {Collaborative}
}

@inproceedings{LG_PTIWRSSE-2012,
  address = {Piscataway, NJ, USA},
  series = {RSSE '12},
  title = {Connecting {{User Stories}} and {{Code}} for {{Test Development}}},
  isbn = {978-1-4673-1759-7},
  abstract = {User Stories are short feature descriptions from the user's point of view. Functional tests ensure that the feature described by a User Story is fully implemented. We present a tool that builds an ontology for code and links completed User Stories in natural language with the related code artifacts. The ontology also contains links to API components that were used to implement the functional tests. Preliminary results show that these links can be used to recommend reusable test steps for new User Stories.},
  timestamp = {2017-01-25T13:59:35Z},
  urldate = {2017-01-25},
  booktitle = {{{Third International Workshop}} on {{Recommendation Systems}} for {{Software Engineering}}},
  publisher = {{IEEE Press}},
  author = {Landh{\"a}u{\ss}er, Mathias and Genaid, Adrian},
  year = {2012},
  keywords = {code mining,functional testing,ontology,reasoning,traceability},
  pages = {33--37},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/4PKZ36BF/Landhäußer and Genaid - 2012 - Connecting User Stories and Code for Test Developm.pdf:application/pdf},
  groups = {Collaborative}
}

@book{Sin_-2013,
  title = {Improving the {{Adoption}} of {{Software Engineering Practices Through Persuasive Interventions}}},
  isbn = {978-1-291-27311-3},
  language = {en},
  timestamp = {2017-04-19T12:46:53Z},
  publisher = {{Lulu.com}},
  author = {Singer, Leif-Gerrit},
  year = {2013},
  note = {Google-Books-ID: vkWiBAAAQBAJ},
  groups = {Collaborative}
}

@inproceedings{Buf+Edw_ITiCSE-2012,
  address = {New York, NY, USA},
  series = {ITiCSE '12},
  title = {Exploring {{Influences}} on {{Student Adherence}} to {{Test}}-Driven {{Development}}},
  isbn = {978-1-4503-1246-2},
  OPTdoi = {10.1145/2325296.2325324},
  abstract = {Test-Driven Development (TDD) is a software development process with a test-first approach that shows promise for improving code quality. Our research addresses concerns raised in both academia and industry about a lack of motivation or acceptance in adopting TDD. In a CS2 class, we used an automated testing tool and post-class surveys to observe patterns of behavior in testing as well as changes in attitudes. We found significant positive outcomes for students following TDD. We also identified obstacles deterring students from adhering to TDD and discuss reasons and possible remedies.},
  timestamp = {2016-10-24T09:37:46Z},
  urldate = {2016-10-24},
  booktitle = {17th {{ACM Annual Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  publisher = {{ACM}},
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  year = {2012},
  keywords = {adherence,affect,agile,automated testing,extreme programming,junit,procrastination,Software Engineering,Test-driven development (TDD),web-cat},
  pages = {105--110},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/BWFXJGV5/Buffardi and Edwards - 2012 - Exploring Influences on Student Adherence to Test-.pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{Buf+Edw_SIGCSE-2013,
  address = {New York, NY, USA},
  series = {SIGCSE '13},
  title = {Impacts of {{Adaptive Feedback}} on {{Teaching Test}}-Driven {{Development}}},
  isbn = {978-1-4503-1868-6},
  OPTdoi = {10.1145/2445196.2445287},
  abstract = {Studies have found that following Test-Driven Development (TDD) can improve code and testing quality. However, a preliminary investigation was consistent with concerns raised by other educators about programmers resisting TDD. In this paper, we describe an adaptive, pedagogical system for tracking and encouraging students' adherence to TDD. Along with an empirical evaluation of the system, we discuss challenges and opportunities for persuading student behavior through adaptive technology.},
  timestamp = {2016-10-24T09:37:46Z},
  urldate = {2016-10-24},
  booktitle = {44th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  publisher = {{ACM}},
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  year = {2013},
  keywords = {adherence,automated testing,instructional technology,Test-driven development (TDD),test-first,unit testing,web-cat},
  pages = {293--298},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/VGHFAFF3/Buffardi and Edwards - 2013 - Impacts of Adaptive Feedback on Teaching Test-driv.pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{Buf+Edw_SIGCSE-2014,
  address = {New York, NY, USA},
  series = {SIGCSE '14},
  title = {A {{Formative Study}} of {{Influences}} on {{Student Testing Behaviors}}},
  isbn = {978-1-4503-2605-6},
  OPTdoi = {10.1145/2538862.2538982},
  abstract = {While Computer Science curricula teach students strategic software development processes, assessment is often product-instead of process-oriented. Test-Driven Development (TDD) has gained popularity in computing education, but evaluating students' adherence to TDD requires analyzing their development processes instead of only their final product. Consequently, we designed an adaptive feedback system for reinforcing incremental testing behaviors. In this paper, we compare the results of the system with different reinforcement schedules and with- or without- visually salient testing goals. We analyzed snapshots of students' programming projects gathered during development and interviewed students at the end of the academic term. From our findings, we identify potential for influencing student development behaviors and suggest future direction for designing adaptive reinforcement.},
  timestamp = {2016-10-24T09:37:46Z},
  urldate = {2016-10-24},
  booktitle = {45th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  publisher = {{ACM}},
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  year = {2014},
  keywords = {adaptive feedback,automated testing,instructional technology,software development process,test-driven development,test-first,unit testing,web-cat},
  pages = {597--602},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/4FPGR75D/Buffardi and Edwards - 2014 - A Formative Study of Influences on Student Testing.pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{Ear+Fre+Mar+Art_EUROMICRO-2014,
  title = {Teaching {{Students Property}}-{{Based Testing}}},
  OPTdoi = {10.1109/SEAA.2014.74},
  abstract = {Testing is a crucial aspect of the development of dependable embedded systems, and therefore a significant effort is put into researching and developing efficient testing techniques. However, testing is not normally taught in specific courses at many universities, but rather as a peripheral activity to programming. In this paper, we report on three separate experiences at teaching an advanced testing technique, property-based testing, and a supporting tool, QuviQ Quick Check, to both undergraduate and master students.},
  timestamp = {2016-10-24T09:37:46Z},
  booktitle = {2014 40th {{EUROMICRO Conference}} on {{Software Engineering}} and {{Advanced Applications}}},
  author = {Earle, C. B. and Fredlund, L. {\AA} and Mari{\~n}o, J. and Arts, T.},
  month = aug,
  year = {2014},
  keywords = {advanced testing technique,computer science education,courses,dependable embedded system development,educational courses,Educational institutions,embedded systems,further education,java,Libraries,master students,Programming,program testing,Property-Based Testing,QuviQ QuickCheck,Software,supporting tool,teaching,Testing,Testing and debugging,testing techniques,undergraduate students,universities},
  pages = {437--442},
  file = {IEEE Xplore Full Text PDF:/home/mm894/Documents/Zotero/storage/DA3JRW73/Earle et al. - 2014 - Teaching Students Property-Based Testing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mm894/Documents/Zotero/storage/FUIS34I4/6928850.html:text/html},
  groups = {CSE}
}

@inproceedings{Jeu+vBin+Ger+Hee_CSERC-2014,
  address = {New York, NY, USA},
  series = {CSERC '14},
  title = {Model {{Solutions}} and {{Properties}} for {{Diagnosing Student Programs}} in {{Ask}}-{{Elle}}},
  isbn = {978-1-4503-3347-4},
  OPTdoi = {10.1145/2691352.2691355},
  abstract = {Ask-Elle is an interactive tutor that supports the stepwise development of simple functional programs. Using Ask-Elle students receive feedback about whether or not they are on the right track, they can ask for a hint when they are stuck, and get suggestions about how to refactor their program. Our tutor generates this feedback from model solutions and properties that a solution should satisfy. This paper studies the feasibility of using model solutions together with the desired properties of solutions to analyse the work of a student. It describes an experiment in which we analyse almost 3500 log entries from students using Ask-Elle to solve functional programming exercises, to determine how many of these programs are diagnosed correctly based on model solutions and the desired properties of solutions. Ask-Elle manages to correctly diagnose 82.9\% of the student programs. A further analysis of the student programs and the diagnoses shows that adding some reasonable model solutions, properties of model solutions, and general program transformations would increase this percentage to 92.9\%.},
  timestamp = {2016-10-24T09:37:46Z},
  urldate = {2016-10-24},
  booktitle = {{{Computer Science Education Research Conference}}},
  publisher = {{ACM}},
  author = {Jeuring, Johan and {van Binsbergen}, L. Thomas and Gerdes, Alex and Heeren, Bastiaan},
  year = {2014},
  keywords = {functional programming,Haskell,tutoring},
  pages = {31--40},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/P2M2V5DT/Jeuring et al. - 2014 - Model Solutions and Properties for Diagnosing Stud.pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{GTH+_P4ATSCSE-2016,
  address = {New York, NY, USA},
  series = {SIGCSE '16},
  title = {Differences in the {{Learning Principles Dominating Student}}-{{Student}} vs. {{Student}}-{{Instructor Interactions While Working}} on {{Programming Tasks}}},
  isbn = {978-1-4503-3685-7},
  OPTdoi = {10.1145/2839509.2844627},
  abstract = {Peer learning principles have been successfully applied to novice programmers. Pedagogies such as Pair Programming, Peer Testing, Peer review of code or tests, or, more generally Peer Instruction, have repeatedly demonstrated their effectiveness in improving both individual performance and retention rates. This paper proposes to supplement the existing literature by investigating how students interact with one another during collaborative programming tasks. More specifically, we are interested in comparing the learning principles used during student-student interactions with those used during student-instructor or student-teaching assistant dialogs. Students in online and face to face courses, who worked collaboratively on programming assignments, were surveyed to gain an understanding of the frequency with which they engaged in specific activities. These that are representative of the learning principles that have been supported by research to promote learning. Results suggest that some learning principles, may be absent from student-student interactions. We discuss how the success of collaborative programming pedagogies put into question the role of these principles and whether they may contribute to further improve peer-based approaches.},
  timestamp = {2017-06-17T01:40:15Z},
  booktitle = {47th {{ACM Technical Symposium}} on {{Computing Science Education}}},
  publisher = {{ACM}},
  author = {Gaspar, Alessio and Torsella, Joni and Honken, Nora and Sohoni, Sohum and Arnold, Colin},
  year = {2016},
  keywords = {learning principles,novice programmers,peer learning},
  pages = {255--260},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/ZUK35V7N/Gaspar et al. - 2016 - Differences in the Learning Principles Dominating .pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{GLBT_P1AASCITE-2013a,
  address = {New York, NY, USA},
  series = {SIGITE '13},
  title = {A {{Preliminary Review}} of {{Undergraduate Programming Students}}' {{Perspectives}} on {{Writing Tests}}, {{Working}} with {{Others}}, \& {{Using Peer Testing}}},
  isbn = {978-1-4503-2239-3},
  OPTdoi = {10.1145/2512276.2512301},
  abstract = {Techniques such as Pair Programming, or allowing students to run their programs against a reference test harness, have demonstrated their effectiveness in improving grades or retention rates. This paper proposes to supplement the existing literature by investigating students' perceptions of the benefits of writing tests, working with other students and using Peer Testing. Responses to an online anonymous survey cast new light on the relation between testing and programming and confirm previously postulated limitations of collaborative approaches; i.e. the unbalanced nature of contributions and lack of didactic interactions in student groups. We then examine how Peer Testing is perceived and discuss its relation to both collaboration and test-based pedagogies.},
  timestamp = {2017-06-19T11:19:34Z},
  booktitle = {14th {{Annual ACM SIGITE Conference}} on {{Information Technology Education}}},
  publisher = {{ACM}},
  author = {Gaspar, Alessio and Langevin, Sarah and Boyer, Naomi and Tindell, Ralph},
  year = {2013},
  keywords = {novice programmers,peer testing,programming pedagogy},
  pages = {109--114},
  file = {ACM Full Text PDF:/home/mm894/Documents/Zotero/storage/J6EZT83H/Gaspar et al. - 2013 - A Preliminary Review of Undergraduate Programming .pdf:application/pdf},
  groups = {CSE}
}

@inproceedings{PKF_2SAPLS2-2017,
  address = {Dagstuhl, Germany},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  title = {Teaching {{Programming Languages}} by {{Experimental}} and {{Adversarial Thinking}}},
  volume = {71},
  isbn = {978-3-95977-032-3},
  OPTdoi = {10.4230/LIPIcs.SNAPL.2017.13},
  timestamp = {2017-06-23T08:14:44Z},
  booktitle = {2nd {{Summit}} on {{Advances}} in {{Programming Languages}} ({{SNAPL}} 2017)},
  publisher = {{Schloss Dagstuhl\textendash{}Leibniz-Zentrum fuer Informatik}},
  author = {Pombrio, Justin and Krishnamurthi, Shriram and Fisler, Kathi},
  editor = {Lerner, Benjamin S. and Bod{\'\i}k, Rastislav and Krishnamurthi, Shriram},
  year = {2017},
  keywords = {Education,interpreters,mystery languages,paradigms},
  pages = {13:1--13:9},
  file = {Full Text PDF:/home/mm894/Documents/Zotero/storage/NVS277R3/Pombrio et al. - 2017 - Teaching Programming Languages by Experimental and.pdf:application/pdf;Snapshot:/home/mm894/Documents/Zotero/storage/N45BHHDX/7117.html:text/html},
  groups = {CSE}
}

@incollection{Hil+Nel+McDo+McDo+Met+Dig+Sha+Hal_XP-2016,
  series = {Lecture Notes in Business Information Processing},
  title = {{{TDDViz}}: {{Using Software Changes}} to {{Understand Conformance}} to {{Test Driven Development}}},
  copyright = {\textcopyright{}2016 The Author(s)},
  isbn = {978-3-319-33514-8 978-3-319-33515-5},
  shorttitle = {{{TDDViz}}},
  abstract = {A bad software development process leads to wasted effort and inferior products. In order to improve a software process, it must be first understood. Our unique approach in this paper uses code and test changes to understand conformance to the Test Driven Development (TDD) process. We designed and implemented TDDViz, a tool that supports developers in better understanding how they conform to TDD. TDDViz supports this understanding by providing novel visualizations of developers' TDD process. To enable TDDViz 's visualizations, we developed a novel automatic inferencer that identifies the phases that make up the TDD process solely based on code and test changes. We evaluate TDDViz using two complementary methods: a controlled experiment with 35 participants to evaluate the visualization, and a case study with 2601 TDD Sessions to evaluate the inference algorithm. The controlled experiment shows that, in comparison to existing visualizations, participants performed significantly better when using TDDViz to answer questions about code evolution. In addition, the case study shows that the inferencing algorithm in TDDViz infers TDD phases with an accuracy (F-measure) of 87\%.},
  language = {en},
  timestamp = {2016-09-16T11:53:37Z},
  number = {251},
  urldate = {2016-09-16},
  booktitle = {Agile {{Processes}}, in {{Software Engineering}}, and {{Extreme Programming}}},
  publisher = {{Springer International Publishing}},
  author = {Hilton, Michael and Nelson, Nicholas and McDonald, Hugh and McDonald, Sean and Metoyer, Ron and Dig, Danny},
  editor = {Sharp, Helen and Hall, Tracy},
  month = may,
  year = {2016},
  keywords = {Business Information Systems,Development process,Management of Computing and Information Systems,Software Engineering,Software Management,Software visualization,Test Driven Development},
  pages = {53--65},
  file = {Full Text PDF:/home/mm894/Documents/Zotero/storage/I6BCW3JA/Hilton et al. - 2016 - TDDViz Using Software Changes to Understand Confo.pdf:application/pdf;Snapshot:/home/mm894/Documents/Zotero/storage/6E5S8WFN/978-3-319-33515-5_5.html:text/html},
  groups = {TDD},
  OPTdoi = {10.1007/978-3-319-33515-5_5}
}

@article{Mun+Moa+Pet_jIST-2014-v56n4,
  title = {Considering Rigor and Relevance When Evaluating Test Driven Development: {{A}} Systematic Review},
  volume = {56},
  issn = {0950-5849},
  shorttitle = {Considering Rigor and Relevance When Evaluating Test Driven Development},
  OPTdoi = {10.1016/j.infsof.2014.01.002},
  abstract = {Context
Test driven development (TDD) has been extensively researched and compared to traditional approaches (test last development, TLD). Existing literature reviews show varying results for TDD.
Objective
This study investigates how the conclusions of existing literature reviews change when taking two study quality dimension into account, namely rigor and relevance.
Method
In this study a systematic literature review has been conducted and the results of the identified primary studies have been analyzed with respect to rigor and relevance scores using the assessment rubric proposed by Ivarsson and Gorschek 2011. Rigor and relevance are rated on a scale, which is explained in this paper. Four categories of studies were defined based on high/low rigor and relevance.
Results
We found that studies in the four categories come to different conclusions. In particular, studies with a high rigor and relevance scores show clear results for improvement in external quality, which seem to come with a loss of productivity. At the same time high rigor and relevance studies only investigate a small set of variables. Other categories contain many studies showing no difference, hence biasing the results negatively for the overall set of primary studies. Given the classification differences to previous literature reviews could be highlighted.
Conclusion
Strong indications are obtained that external quality is positively influenced, which has to be further substantiated by industry experiments and longitudinal case studies. Future studies in the high rigor and relevance category would contribute largely by focusing on a wider set of outcome variables (e.g. internal code quality). We also conclude that considering rigor and relevance in TDD evaluation is important given the differences in results between categories and in comparison to previous reviews.},
  timestamp = {2016-09-16T11:52:11Z},
  number = {4},
  urldate = {2016-09-16},
  journal = {Information and Software Technology},
  author = {Munir, Hussan and Moayyed, Misagh and Petersen, Kai},
  month = apr,
  year = {2014},
  keywords = {External code quality,Internal code quality,Productivity,Test-driven development (TDD),Test-last development (TLD)},
  pages = {375--394},
  file = {ScienceDirect Full Text PDF:/home/mm894/Documents/Zotero/storage/424WTTVZ/Munir et al. - 2014 - Considering rigor and relevance when evaluating te.pdf:application/pdf;ScienceDirect Snapshot:/home/mm894/Documents/Zotero/storage/FC96HUQV/S0950584914000135.html:text/html},
  groups = {TDD}
}

@comment{jabref-meta: databaseType:bibtex;}
@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:BDD-QC\;0\;;
1 ExplicitGroup:Cloud-Computing\;0\;;
1 ExplicitGroup:Collaborative\;0\;;
1 ExplicitGroup:CSE\;0\;;
1 ExplicitGroup:TDD\;0\;;
}

